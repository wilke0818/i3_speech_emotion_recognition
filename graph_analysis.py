import numpy as np
import os
import json
import matplotlib.pyplot as plt
from datetime import datetime

import argparse, sys
from tensorflow.python.summary.summary_iterator import summary_iterator

parser=argparse.ArgumentParser()

parser.add_argument("--output_path", help="Where to save the graph. Should include file name. If not set then attempts to show graph")
parser.add_argument("--input_path", help="Input path. Defaults to ./logs and must follow subdirectory structure of /model_name/seed/runs/auto_generated_log_folder_name")

args=parser.parse_args()

#TODO make file modular
results = {}

#Assumes the logs base file is in the logs subdirectory (ie the logs go logs/model_name/seed/runs/auto_generated_log_folder_name/)
if args.input_path:
  log_path = args.input_path
else:
  log_path = './logs'
models = os.listdir(log_path)

for model in models:
  model_path = os.path.join(log_path, model)
  if not os.path.isdir(model_path):
    continue
  
  results[model] = {}
  for model_run in os.listdir(model_path): 
    model_run_path = os.path.join(model_path,model_run)
    if os.path.isdir(model_run_path):
      results[model][model_run] = {'eval_loss': [], 'eval_accuracy': [], 'train_loss': [], 'epochs': []}
      
      sub_path = os.path.join(model_run_path, 'runs')
      
      #If there was more than one training attempted for this model+seed combo, we want the logs of the most recent run
      if len(os.listdir(sub_path)) >= 1:
        #list of all log subdirectory paths for this model+seed
        all_sub_paths = [os.path.join(sub_path, sub_sub) for sub_sub in os.listdir(sub_path) if os.path.isdir(os.path.join(sub_path, sub_sub))]
        
        #The autogenerated directories have a given naming convention of "shortened month name+day_hour run_minute_seconds"
        #So we create a parallel list of datetime objects that represent the creation time of each log subdirectory
        all_sub_path_times = [datetime.strptime(sub_sub[0:13], '%b%d_%H-%M-%S') for sub_sub in os.listdir(sub_path) if os.path.isdir(os.path.join(sub_path, sub_sub))]

        #Sort the subdirectory paths using the creation times
        sorted_all_sub_paths = sorted(all_sub_paths, key=lambda x:all_sub_path_times[all_sub_paths.index(x)])

        #Grab the most recent log subdirectory
        sub_path = sorted_all_sub_paths[-1]
      elif len(os.listdir(sub_path)) == 1:
        sub_path = os.listdir(sub_path)[0]
      else: #if there were no logs for this seed, just continue onward; this should never be the case
        continue
      print(sub_path)
      if os.path.isdir(sub_path):
        
        #there should be 2 log files: a tensorflow log file and a logs.txt file; the tensorflow file in fact contains all the information we want 
        other_log = [os.path.join(sub_path, f) for f in os.listdir(sub_path) if f!='logs.txt'][0]

        for e in summary_iterator(other_log):
          for v in e.summary.value:
            if v.tag == 'train/loss':
              results[model][model_run]['train_loss'].append(v.simple_value)
            elif v.tag=='eval/loss':
              results[model][model_run]['eval_loss'].append(v.simple_value)
            elif v.tag=='eval/accuracy':
              results[model][model_run]['eval_accuracy'].append(v.simple_value)
            elif v.tag == 'train/epoch':
              #Weirdly every evaluation+training log in this file generates the number of epochs run twice, so we only want to count each once
              if len(results[model][model_run]['epochs'])==0 or results[model][model_run]['epochs'][-1] != v.simple_value:
                results[model][model_run]['epochs'].append(v.simple_value)

print(results)
fig, (ax1, ax2) = plt.subplots(1,2, figsize=(14,10), sharex=True)

'''
#Finds the seed for each model that generated the best eval loss and accuracy and uses that as the model to graph
#TODO make this functionality dynamic/allow user to choose what they want graphed
best_model_map = {}
for model in results:
  min_eval_loss = 10000
  max_eval_acc = -1
  best_model_run_loss = -1
  best_model_run_acc = -1
  best_model_map[model] = {}
  for model_run in results[model]:
    #model_result_loss = min(results[model][model_run]['eval_loss'])
    #model_result_acc = max(results[model][model_run]['eval_accuracy'])
    model_result_loss = results[model][model_run]['eval_loss'][-1]
    model_result_acc = results[model][model_run]['eval_accuracy'][-1]
    if model_result_loss < min_eval_loss:
      min_eval_loss = model_result_loss
      best_model_run_loss = model_run
    if model_result_acc > max_eval_acc:
      max_eval_acc = model_result_acc
      best_model_run_acc = model_run
  best_model_map[model]['eval_loss'] = best_model_run_loss
  best_model_map[model]['eval_accuracy'] = best_model_run_acc


for model in results:
  #TODO clean up this code
  ax1.plot(results[model][best_model_map[model]['eval_accuracy']]['epochs'],results[model][best_model_map[model]['eval_accuracy']]['eval_accuracy'], label=model)

  #For loss, we will also plot the training loss as a dashed line of the same color
  last_line = ax2.plot(results[model][best_model_map[model]['eval_loss']]['epochs'],results[model][best_model_map[model]['eval_loss']]['eval_loss'])
  
  ax2.plot(results[model][best_model_map[model]['eval_loss']]['epochs'],results[model][best_model_map[model]['eval_loss']]['train_loss'], color=last_line[0].get_color(), linestyle='dashed')
'''
for model in results:
  #TODO clean up this code
  ax1.plot(results[model]['0']['epochs'],results[model]['0']['eval_accuracy'], label=model)

  #For loss, we will also plot the training loss as a dashed line of the same color
  last_line = ax2.plot(results[model]['0']['epochs'],results[model]['0']['eval_loss'])
  
  ax2.plot(results[model]['0']['epochs'],results[model]['0']['train_loss'], color=last_line[0].get_color(), linestyle='dashed')
ax1.set(title='Eval Accuracy')
ax1.set(ylabel="Percentage")
ax2.set(title='Loss')
ax2.set(ylabel="Cross Entropy Loss")

fig.supxlabel("Epoch number")

lines = []
labels = []
for ax in fig.axes:
    Line, Label = ax.get_legend_handles_labels()
    lines.extend(Line)
    labels.extend(Label)
fig.legend(lines, labels, loc='upper right')


if args.output_path:
  fig.savefig(args.output_path)
else:
  plt.show()
